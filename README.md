# Front-Page
## Summary of my key ML projects, with links

### `Taster' personal project

&nbsp;&nbsp;&nbsp;&nbsp;[gen-text-and-image](https://github.com/AndrewWren/gen-text-and-image)

<table><tr><td valign="center">
PROMPT <td> -gen-> <td> 'Portrait of the actress Marlene Dietrich' <td> -gen-> <td> 
<img src="https://github.com/AndrewWren/gen-text-and-image/blob/main/examples/Good/Portrait_of_the_actress_Marlene_Dietrich.jpg?raw=true" width="60"></tr></table>

I used a transformer text generator, trained with an appropriate prompt, to generate a very short piece of text. This is fed to a stable diffusion image generator to generate a corresponding image.

### UCL MSc Machine Learning 2021-22 

#### MSc Thesis: *Learning directed acyclic graphs by backpropagation*

Developed a framework for learning directed acyclic graphs via discrete backpropagation, testing it on synthetic and real data, with competitive results which proved the concept.

I learnt about discrete backpropagation techniques and about combinatoric & continuous DAG-finding algorithms. I also learnt about defining and organising a project of this nature and scale in a short time period.

&nbsp;&nbsp;&nbsp;&nbsp;[Thesis repo](https://github.com/DAG-DB/DAG-DB)

&nbsp;&nbsp;&nbsp;&nbsp;[Accepted as NeurIPS&nbsp;2022 workshop paper. Linked soon]()

#### MSc Statistical Natural Language Processing group project: *Learning from clue structure to solve cryptic crosswords*

Originated and coded structural ideas we used for our solver.  This enabled us to get very close to state-of-the-art mid-size transformer performance – with only a relatively small dataset.  Outstanding Distinction.

I learnt about working in a team of peers, working together to steer and develop a project on a very short timescale.  I also learnt about cryptic crosswords and how they are structured.

&nbsp;&nbsp;&nbsp;&nbsp;[Group Project repo](https://gitlab.com/jesus.solano/ucl-nlp-coursework)

### Personal projects

#### NLearn

Developed two reinforcement learning agents who “invent” a language to communicate a varying random message successfully.  Agent “Alice” had to ceeate a binary code language, and Agent “Bob” had to learn to understand it.  They did so without any outside help, using only knowledge of how close Bob’s guess was in each step of the game.

I learnt how to define and optimise a multi-agent reinforcement learning challenge, and how to manage multiple experiments.

&nbsp;&nbsp;&nbsp;&nbsp;[NLearn repo](https://github.com/AndrewWren/NLearn)

#### Quasar mass machine learning

Processed astrophysical data and built a neural net to predict the mass of supermassive black holes from their “quasar” emissions.  Within the distribution of quasars I was targeting, this achieved predictions to within current observational estimates.

I learnt how to shape complex data for machine learning and set up a simple model.  I also learnt how difficult it can be to extend to "out-of-distribution" data. 

&nbsp;&nbsp;&nbsp;&nbsp;[Quasar mass machine learning repo](https://github.com/AndrewWren/Quasar-mass-machine-learning)
